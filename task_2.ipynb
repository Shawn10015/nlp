{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "\n",
    "def prepare_content(content):\n",
    "    prepared_words = nlp(content)\n",
    "\n",
    "    words = [word.lemma_ for word in prepared_words if word.is_alpha and not word.is_stop]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>processed_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>style</td>\n",
       "      <td>Rolex наградит победителей регаты\\tПарусная го...</td>\n",
       "      <td>[rolex, наградить, победитель, регата, парусны...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sport</td>\n",
       "      <td>Матс Сундин стал советником тренера сборной Шв...</td>\n",
       "      <td>[матс, сундин, советник, тренер, сборная, швец...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>media</td>\n",
       "      <td>Брендом года по версии EFFIE впервые стал горо...</td>\n",
       "      <td>[бренд, год, версия, effie, впервые, город, гр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>economics</td>\n",
       "      <td>Цена нефти WTI снизилась после публикации данн...</td>\n",
       "      <td>[цена, нефть, wti, снизиться, публикация, запа...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>economics</td>\n",
       "      <td>Сбербанк распродаст другим банкирам миллиардны...</td>\n",
       "      <td>[сбербанк, распродать, банкир, миллиардный, до...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>economics</td>\n",
       "      <td>Бывший пропагандист Буша нашел работу в торгов...</td>\n",
       "      <td>[бывший, пропагандист, буша, найти, работа, то...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>travel</td>\n",
       "      <td>Россияне предпочли смартфон любимому человеку ...</td>\n",
       "      <td>[россиянин, предпочесть, смартфон, любимый, че...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>life</td>\n",
       "      <td>Потерявшаяся пять недель назад американка найд...</td>\n",
       "      <td>[потеряться, пять, неделя, американка, найти, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>media</td>\n",
       "      <td>НТВ покажет решающие матчи \"Зенита\" и ЦСКА в Л...</td>\n",
       "      <td>[нтв, показать, решающий, матч, зенит, цска, л...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>forces</td>\n",
       "      <td>Полонского проверят на вменяемость и наркозави...</td>\n",
       "      <td>[полонский, проверить, вменяемость, наркозавис...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                            content  \\\n",
       "0         style  Rolex наградит победителей регаты\\tПарусная го...   \n",
       "1         sport  Матс Сундин стал советником тренера сборной Шв...   \n",
       "2         media  Брендом года по версии EFFIE впервые стал горо...   \n",
       "3     economics  Цена нефти WTI снизилась после публикации данн...   \n",
       "4     economics  Сбербанк распродаст другим банкирам миллиардны...   \n",
       "...         ...                                                ...   \n",
       "9995  economics  Бывший пропагандист Буша нашел работу в торгов...   \n",
       "9996     travel  Россияне предпочли смартфон любимому человеку ...   \n",
       "9997       life  Потерявшаяся пять недель назад американка найд...   \n",
       "9998      media  НТВ покажет решающие матчи \"Зенита\" и ЦСКА в Л...   \n",
       "9999     forces  Полонского проверят на вменяемость и наркозави...   \n",
       "\n",
       "                                      processed_content  \n",
       "0     [rolex, наградить, победитель, регата, парусны...  \n",
       "1     [матс, сундин, советник, тренер, сборная, швец...  \n",
       "2     [бренд, год, версия, effie, впервые, город, гр...  \n",
       "3     [цена, нефть, wti, снизиться, публикация, запа...  \n",
       "4     [сбербанк, распродать, банкир, миллиардный, до...  \n",
       "...                                                 ...  \n",
       "9995  [бывший, пропагандист, буша, найти, работа, то...  \n",
       "9996  [россиянин, предпочесть, смартфон, любимый, че...  \n",
       "9997  [потеряться, пять, неделя, американка, найти, ...  \n",
       "9998  [нтв, показать, решающий, матч, зенит, цска, л...  \n",
       "9999  [полонский, проверить, вменяемость, наркозавис...  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_data = []\n",
    "\n",
    "with open('news.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        category, title_content = line.strip().split('\\t', 1)\n",
    "        prepared_data.append([category, title_content])\n",
    "df = pd.DataFrame(prepared_data, columns=['category', 'content'])\n",
    "\n",
    "df['processed_content'] = df['content'].apply(prepare_content)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avarage Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(df['processed_content'], vector_size=100, window=5, min_count=1, workers=12)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec.load('word2vec.model')\n",
    "\n",
    "def news_vector(word2vec_model, words):\n",
    "    tokens = [word for word in words if word in word2vec_model.wv.key_to_index]\n",
    "    if len(tokens) == 0:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    return np.mean(word2vec_model.wv[tokens], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news_vector'] = df['processed_content'].apply(lambda x: news_vector(word2vec_model, x))\n",
    "\n",
    "vectors = np.array(df['news_vector'].tolist())\n",
    "labels = df['category']\n",
    "\n",
    "vectors_train, vectors_test, labels_train, labels_test = train_test_split(vectors, labels, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.67      0.03      0.05        72\n",
      "     culture       0.83      0.88      0.85       268\n",
      "   economics       0.70      0.89      0.78       273\n",
      "      forces       0.63      0.75      0.69       148\n",
      "        life       0.69      0.83      0.75       242\n",
      "       media       0.82      0.80      0.81       309\n",
      "     science       0.85      0.72      0.78       306\n",
      "       sport       0.97      0.97      0.97       308\n",
      "       style       1.00      0.67      0.80        24\n",
      "      travel       0.85      0.22      0.35        50\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.80      0.67      0.68      2000\n",
      "weighted avg       0.80      0.79      0.78      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(vectors_train, labels_train)\n",
    "\n",
    "labels_pred = svm.predict(vectors_test)\n",
    "print(classification_report(labels_test, labels_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tf_idf'] = df['processed_content'].apply(' '.join)\n",
    "\n",
    "tf_idf_vector = TfidfVectorizer()\n",
    "\n",
    "tf = tf_idf_vector.fit_transform(df['tf_idf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['category']\n",
    "tf_train, tf_test, labels_train, labels_test = train_test_split(tf, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.73      0.52      0.61        86\n",
      "     culture       0.91      0.94      0.93       282\n",
      "   economics       0.84      0.88      0.86       250\n",
      "      forces       0.78      0.86      0.82       157\n",
      "        life       0.83      0.85      0.84       250\n",
      "       media       0.89      0.86      0.88       288\n",
      "     science       0.91      0.87      0.89       282\n",
      "       sport       0.96      0.96      0.96       334\n",
      "       style       0.89      0.80      0.84        40\n",
      "      travel       0.73      0.77      0.75        31\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.85      0.83      0.84      2000\n",
      "weighted avg       0.87      0.88      0.87      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_svm = LinearSVC()\n",
    "tf_svm.fit(tf_train, labels_train)\n",
    "\n",
    "labels_pred = tf_svm.predict(tf_test)\n",
    "print(classification_report(labels_test, labels_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
