{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"fill-mask\", model='distilroberta-base')\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence(sentence):\n",
    "    words = sentence.split()\n",
    "    spilt_num_word = max(1, len(words) // 2)\n",
    "    mask_word = random.sample(range(len(words)), spilt_num_word)\n",
    "\n",
    "    mask_sentence = []\n",
    "\n",
    "    for i in range(len(words)):\n",
    "        if i not in mask_word:\n",
    "            mask_sentence.append(words[i])\n",
    "        else:\n",
    "            mask_sentence.append(pipe.tokenizer.mask_token)\n",
    "    mask_sentence = \" \".join(mask_sentence)\n",
    "\n",
    "    predictions = pipe(mask_sentence)\n",
    "\n",
    "    new_words = words.copy()\n",
    "\n",
    "    for i, index in enumerate(mask_sentence):\n",
    "        if i < len(predictions) and 'token_str' in predictions[i]:\n",
    "            new_words = predictions[i]['token_str']\n",
    "\n",
    "    new_sentence = \" \".join(new_words)\n",
    "\n",
    "    generate = generator(new_sentence, max_length=100, num_return_sequences=1, temperature=0.6, do_sample=True)\n",
    "    generate_sentence = generate[0]['generated_text']\n",
    "\n",
    "    return generate_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: After your workout, remember to focus on maintaining a good water balance.\n",
      "\n",
      "A good water balance is one that gives you a good chance to get the best out of your workout.\n",
      "\n",
      "If you're doing water work, you'll want to put on some water.\n",
      "\n",
      "A good water balance also means that you'll be working out at least 3 times a week.\n",
      "\n",
      "If you're doing water work twice a week, do it at once.\n",
      "\n",
      "If you're doing water\n",
      "Similarity: 0.857189953327179\n"
     ]
    }
   ],
   "source": [
    "sentence = \"After your workout, remember to focus on maintaining a good water balance.\"\n",
    "\n",
    "loop_num = 100\n",
    "similar_status = 0.85\n",
    "create_new_sentences = ()\n",
    "\n",
    "for i in range(loop_num):\n",
    "    create_new_sentence = create_sentence(sentence)\n",
    "\n",
    "    if create_new_sentence not in create_new_sentence:\n",
    "        create_new_sentences.add(create_new_sentence)\n",
    "\n",
    "    sentence_emb = sentence_model.encode(sentence, convert_to_tensor=True)\n",
    "    new_sentence_emb = sentence_model.encode(create_new_sentence, convert_to_tensor=True)\n",
    "\n",
    "    similarity = util.pytorch_cos_sim(sentence_emb, new_sentence_emb)[0][0].item()\n",
    "\n",
    "    if similarity > similar_status:\n",
    "        break\n",
    "\n",
    "print(f\"Sentence: {create_new_sentence}\\nSimilarity: {similarity}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
